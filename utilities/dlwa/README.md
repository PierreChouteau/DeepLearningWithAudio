# DLWA

`dlwa.py` is a script that aims to simplify setup and usage of the models studied in the Deep Learning with Audio course by automating as much as possible and integrating some common workarounds for problems. It does not expose all the functionality of the underlying tools, but prints out the commands it executes so that the user may understand what is happening underneath and dive deeper if desired.

`dlwa.py` currently only supports Linux. It includes some special logic to deal with the environment on Aalto systems (mainly the Paniikki computers), but will in theory run on any Linux system with Conda and a CUDA-capable GPU.

## Basics

First, enter the `dlwa` folder containing the script:

```
cd DeepLearningWithAudio/utilities/dlwa
```

`dlwa.py` commands have the form:

```
./dlwa.py MODEL COMMAND [ARGUMENTS ...]
```

The available commands differ for each model. You can always pass the `-h` or `--help` argument to get some basic help about a command, for example:

```
./dlwa.py ddsp train -h
```

```
usage: dlwa.py ddsp train [-h] --dataset_name DATASET_NAME --model_name MODEL_NAME [--custom] ...

positional arguments:
  extra_args

optional arguments:
  -h, --help            show this help message and exit
  --dataset_name DATASET_NAME
  --model_name MODEL_NAME
  --custom
```

## Folder structure

`dlwa.py` comes with a particular folder structure for working with the deep learning models. Here is an explanation of the various folders:

- `conda-env-specs`: Contains `.yml` files that specify which Conda and Pip packages are needed to create the environment for each model.
- `datasets`: Will contain dataset files for some models, generated from audio.
- `inputs`: Will contain input files, usually audio in `.wav` format.
- `lib`: Contains most of the code that makes `dlwa.py` work.
- `misc`: Contains miscellaneous configuration files.
- `models`: Will contain trained models to be used for generating audio.
- `outputs`: Will contains output files generated by some models.
- `repos`: Will contain cloned repositories of the various codebases we use, such as `magenta`.

## Usage

### Setup

```
./dlwa.py ddsp setup
```
Sets up a Conda environment for ddsp, installing all the necessary packages.  
For the other models, change ddsp by their name to set up the different Conda environnement. (eg. `./dlwa.py gansynth setup`, same thing for samplernn and nsynth)


### Dataset, Training 

To go further in the use of the script, you can consult the Azure trainings, which show in detail how to use it:
* [DDSP](../../02_ddsp/training/azure_training.md)
* [GANSynth](../../03_nsynth_and_gansynth/gansynth/training/azure_training.md)
* [SampleRNN](../../05_samplernn/training/azure_samplernn.md) 



### Custom argument, extra_argument

To use a custom argument, add it to the end of the command line: 
```
./dlwa.py MODEL COMMAND [ARGUMENTS ...] \
--custom \
-- \ 
--customArguments ...
```

To use extra argument, add it to the end of the command line: 
```
./dlwa.py MODEL COMMAND [ARGUMENTS ...] \
-- \ 
--extraArguments ...
```

#### DDSP:

For the DDSP model, 2 different scripts can be use with custom arguments or extra_arguments. If you want to use them, you will need to use it as follows:

Note:
- The values below are the one that is used without changing custom arguments.
- All the custom arguments are required by the script. So if you want to change one of them, you will need to use the full command line, with all the custom argument.

- ``` 
  ./dlwa.py ddsp make-dataset --input_name input_folder --dataset_name dataset_folder \
    --custom \
    -- \
    --num_shards 10 \
    --sample_rate 16000 
  ``` 
- ``` 
  ./dlwa.py ddsp train dataset_folder --model_name name_model\
    --custom \
    -- \
    --gin_file models/solo_instrument.gin \
    --gin_file datasets/tfrecord.gin \ 
    --gin_param batch_size=16 \
    --gin_param train_util.train.num_steps=30000 \
    --gin_param train_util.train.steps_per_save=300 \
    --gin_param train_util.Trainer.checkpoints_to_keep=10
  ``` 

#### GANSynth:

For the GANSynth model, 2 different scripts can be use with extra_arguments. If you want to use them, you will need to use it as follows:

Note: The values are the default one.

- ``` 
  ./dlwa.py gansynth chop-audio --input_name mytunes --output_name mysounds_chopped \
    -- \
    --step 64000 \
    --sample_rate 16000 \
    --len 64000 \
    --pitch 32

  ``` 
- ``` 
  ./dlwa.py gansynth make-dataset --dataset_name mydataset --model_name mymodel \
    -- \
    --sample_rate 16000\
    --length 64000
  ``` 


#### SampleRNN:

For the SampleRNN model, 2 different scripts can be use with custom arguments or extra_arguments. If you want to use them, you will need to use it as follows:

Note: 
- The values below are the one that is used without changing custom arguments.
- All the custom arguments are required by the script. So if you want to change one of them, you will need to use the full command line, with all the custom argument.

- ``` 
  ./dlwa.py samplernn chunk-audio --input_name myinputs --output_name myinputs_chunks \
    --custom \
    -- \
    --chunk_length 8000 \
    --overlap 1000
  ``` 
- ``` 
  ./dlwa.py samplernn train --input_name myinputs_chunks --model_name  model_name  --preset lstm-linear-skip \
    --custom \
    -- \
    --batch_size 128 \
    --checkpoint_every 5 \
    --sample_rate 16000 \
    --config_file ./misc/samplernn/lstm-linear-skip.config.json
  ``` 
